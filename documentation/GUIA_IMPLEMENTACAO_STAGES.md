# Guia de Implementa√ß√£o dos 13 Stages Centralizados

## Princ√≠pio Fundamental

**REGRA ABSOLUTA**: Nenhum stage deve ser implementado sem Anthropic API, exceto para:
1. **Carregamento de arquivos** (leitura CSV b√°sica)
2. **Fun√ß√µes muito simples** (contagens, valida√ß√µes estruturais)
3. **Opera√ß√µes de I/O** (salvar checkpoints)

## Status de Implementa√ß√£o dos Stages

### ‚úÖ **Stages Totalmente Implementados com Anthropic**

#### **Stage 03: Text Cleaning**
- **M√≥dulo**: `src/anthropic_integration/text_cleaner.py`
- **Classe**: `AnthropicTextCleaner`
- **M√©todo**: `clean_text_intelligent()`
- **Status**: ‚úÖ Completamente implementado
- **Funcionalidade**: Limpeza contextual preservando significado pol√≠tico

#### **Stage 04: Sentiment Analysis**
- **M√≥dulo**: `src/anthropic_integration/sentiment_analyzer.py`
- **Classe**: `AnthropicSentimentAnalyzer`
- **M√©todo**: `analyze_sentiment_comprehensive()`
- **Status**: ‚úÖ Completamente implementado
- **Funcionalidade**: An√°lise multi-dimensional de sentimentos pol√≠ticos

#### **Stage 05: Topic Modeling**
- **M√≥dulo**: `src/anthropic_integration/topic_interpreter.py`
- **Classe**: `TopicInterpreter`
- **M√©todo**: `interpret_topics_comprehensive()`
- **Status**: ‚úÖ Completamente implementado
- **Funcionalidade**: Interpreta√ß√£o sem√¢ntica de t√≥picos LDA

#### **Stage 07: Clustering**
- **M√≥dulo**: `src/anthropic_integration/cluster_validator.py`
- **Classe**: `ClusterValidator`
- **M√©todo**: `validate_clusters_comprehensive()`
- **Status**: ‚úÖ Completamente implementado
- **Funcionalidade**: Valida√ß√£o e interpreta√ß√£o sem√¢ntica de clusters

#### **Stage 12: Qualitative Analysis**
- **M√≥dulo**: `src/anthropic_integration/qualitative_classifier.py`
- **Classe**: `QualitativeClassifier`
- **M√©todo**: `classify_content_comprehensive()`
- **Status**: ‚úÖ Completamente implementado
- **Funcionalidade**: Classifica√ß√£o de conspira√ß√£o e negacionismo

### üÜï **Stages com M√≥dulos Antropic Rec√©m-Criados**

#### **Stage 02: Encoding Fix**
- **M√≥dulo**: `src/anthropic_integration/smart_encoding_fixer.py`
- **Classe**: `SmartEncodingFixer`
- **M√©todo**: `fix_encoding_intelligent()`
- **Status**: ‚úÖ M√≥dulo criado, integra√ß√£o centralizada
- **Funcionalidade**: Corre√ß√£o contextual de encoding

#### **Stage 02b: Deduplication**
- **M√≥dulo**: `src/anthropic_integration/intelligent_deduplicator.py`
- **Classe**: `IntelligentDeduplicator`
- **M√©todo**: `deduplicate_intelligent()`
- **Status**: ‚úÖ M√≥dulo criado, integra√ß√£o centralizada
- **Funcionalidade**: Deduplica√ß√£o sem√¢ntica avan√ßada

#### **Stage 06: TF-IDF Extraction**
- **M√≥dulo**: `src/anthropic_integration/semantic_tfidf_analyzer.py`
- **Classe**: `SemanticTfidfAnalyzer`
- **M√©todo**: `extract_semantic_tfidf()`
- **Status**: ‚úÖ M√≥dulo criado, integra√ß√£o centralizada
- **Funcionalidade**: TF-IDF com interpreta√ß√£o sem√¢ntica

#### **Stage 09: Domain Extraction**
- **M√≥dulo**: `src/anthropic_integration/intelligent_domain_analyzer.py`
- **Classe**: `IntelligentDomainAnalyzer`
- **M√©todo**: `analyze_domains_intelligent()`
- **Status**: ‚úÖ M√≥dulo criado, integra√ß√£o centralizada
- **Funcionalidade**: Classifica√ß√£o e an√°lise de credibilidade de dom√≠nios

#### **Stage 10: Temporal Analysis**
- **M√≥dulo**: `src/anthropic_integration/smart_temporal_analyzer.py`
- **Classe**: `SmartTemporalAnalyzer`
- **M√©todo**: `analyze_temporal_patterns()`
- **Status**: ‚úÖ M√≥dulo criado, integra√ß√£o centralizada
- **Funcionalidade**: Detec√ß√£o e interpreta√ß√£o de eventos temporais

#### **Stage 11: Network Structure**
- **M√≥dulo**: `src/anthropic_integration/intelligent_network_analyzer.py`
- **Classe**: `IntelligentNetworkAnalyzer`
- **M√©todo**: `analyze_networks_intelligent()`
- **Status**: ‚úÖ M√≥dulo criado, integra√ß√£o centralizada
- **Funcionalidade**: An√°lise de redes com interpreta√ß√£o de comunidades

#### **Stage 13: Review & Reproducibility**
- **M√≥dulo**: `src/anthropic_integration/smart_pipeline_reviewer.py`
- **Classe**: `SmartPipelineReviewer`
- **M√©todo**: `review_pipeline_comprehensive()`
- **Status**: ‚úÖ M√≥dulo criado, integra√ß√£o centralizada
- **Funcionalidade**: Revis√£o inteligente de qualidade do pipeline

### ‚öôÔ∏è **Stages com Implementa√ß√£o B√°sica (Sem AI por Design)**

#### **Stage 01: Data Validation**
- **Raz√£o**: Performance e efici√™ncia para valida√ß√£o estrutural
- **Implementa√ß√£o**: Valida√ß√£o b√°sica de estrutura CSV
- **Funcionalidade**: 
  - Verifica√ß√£o de colunas obrigat√≥rias
  - Contagem de linhas e colunas
  - Detec√ß√£o de valores nulos
  - Valida√ß√£o de tipos b√°sicos

```python
def _execute_traditional_validation(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """Valida√ß√£o tradicional de dados - √öNICO caso sem AI"""
    validation_results = {
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'missing_values': df.isnull().sum().to_dict(),
        'data_types': df.dtypes.astype(str).to_dict(),
        'validation_method': 'traditional'
    }
    return df, validation_results
```

#### **Stage 01b: Feature Extraction**
- **M√≥dulo**: `src/utils/auto_column_detector.py` (AutoColumnDetectorAI)
- **Status**: ‚úÖ J√° utiliza Anthropic
- **Funcionalidade**: Extra√ß√£o inteligente de caracter√≠sticas pol√≠ticas

#### **Stage 08: Hashtag Normalization**
- **Status**: üîÑ Precisa de m√≥dulo Anthropic espec√≠fico
- **Implementa√ß√£o Atual**: Normaliza√ß√£o b√°sica por regex
- **Implementa√ß√£o Necess√°ria**: Agrupamento sem√¢ntico inteligente

```python
# Implementa√ß√£o b√°sica tempor√°ria (apenas para I/O)
def _execute_traditional_hashtag_normalization(self, df: pd.DataFrame):
    """Normaliza√ß√£o b√°sica - TEMPOR√ÅRIA at√© m√≥dulo AI"""
    # Apenas limpeza b√°sica e lowercase
    # TODO: Implementar m√≥dulo Anthropic espec√≠fico
```

## Padr√µes de Implementa√ß√£o

### 1. **Template de M√≥dulo Anthropic**

```python
class IntelligentStageModule(AnthropicBase):
    """
    M√≥dulo inteligente para Stage XX
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # Configura√ß√µes espec√≠ficas do stage
        stage_config = config.get('stage_config_section', {})
        self.param1 = stage_config.get('param1', default_value)
    
    def analyze_intelligent(self, df: pd.DataFrame, **kwargs) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        M√©todo principal de an√°lise inteligente
        
        Args:
            df: DataFrame com dados
            **kwargs: Par√¢metros espec√≠ficos
            
        Returns:
            Tuple[DataFrame processado, M√©tricas de an√°lise]
        """
        self.logger.info("Iniciando an√°lise inteligente")
        
        # Processamento em chunks se necess√°rio
        if len(df) > 10000:
            return self._process_in_chunks(df, **kwargs)
        
        # An√°lise direta para datasets menores
        return self._analyze_full_dataset(df, **kwargs)
    
    def _process_in_chunks(self, df: pd.DataFrame, **kwargs) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """Processamento em chunks para datasets grandes"""
        chunk_size = 5000
        results = []
        
        for i in range(0, len(df), chunk_size):
            chunk = df.iloc[i:i+chunk_size]
            chunk_result = self._analyze_chunk(chunk, **kwargs)
            results.append(chunk_result)
        
        # Consolidar resultados
        return self._consolidate_results(results)
    
    def _analyze_chunk(self, chunk: pd.DataFrame, **kwargs) -> Dict[str, Any]:
        """An√°lise de um chunk espec√≠fico com AI"""
        # Preparar dados para an√°lise
        sample_data = self._prepare_sample_for_ai(chunk)
        
        prompt = f"""
        Analise este chunk de dados do Telegram brasileiro (2019-2023):
        
        CONTEXTO: {self._get_brazilian_context()}
        
        DADOS: {sample_data}
        
        TAREFA ESPEC√çFICA: [Descrever tarefa do stage]
        
        Responda em JSON com an√°lise espec√≠fica para este stage.
        """
        
        try:
            response = self.create_message(
                prompt=prompt,
                stage=f'XX_stage_name',
                operation='analyze_chunk'
            )
            
            analysis = self.parse_json_response(response)
            return analysis
            
        except Exception as e:
            self.logger.error(f"Erro na an√°lise AI: {e}")
            raise
```

### 2. **Template de Integra√ß√£o no Pipeline Executor**

```python
def execute_stage_XX_description(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """Stage XX: Descri√ß√£o - Funcionalidade espec√≠fica"""
    self.logger.info("üéØ Executando Stage XX: Descri√ß√£o")
    
    stage_instance = self.stage_factory.create_stage('XX_stage_name')
    
    if hasattr(stage_instance, 'analyze_intelligent'):  # Usando AI
        return stage_instance.analyze_intelligent(
            df, 
            param1=self.config.get('stage_config', {}).get('param1', default)
        )
    else:  # APENAS para fun√ß√µes muito simples
        return self._execute_simple_operation(df)

def _execute_simple_operation(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """
    Opera√ß√£o simples - APENAS para:
    - Carregamento de arquivos
    - Contagens b√°sicas  
    - Valida√ß√µes estruturais
    - I/O operations
    """
    # Implementa√ß√£o extremamente b√°sica
    simple_result = {
        'method': 'simple_operation',
        'rows_processed': len(df),
        'operation': 'basic_structural_check'
    }
    
    return df, simple_result
```

### 3. **Template de Factory Integration**

```python
def _create_stage_XX(self, **kwargs) -> Any:
    """Stage XX: Descri√ß√£o"""
    use_anthropic = self.config.get('stage_config', {}).get('use_anthropic', True)  # Padr√£o TRUE
    
    if use_anthropic and self.anthropic_available:
        try:
            from src.anthropic_integration.intelligent_module import IntelligentModule
            self.logger.info("ü§ñ Stage XX: Usando an√°lise inteligente")
            return IntelligentModule(self.config)
        except Exception as e:
            self.logger.warning(f"Falha na AI Stage XX: {e}")
            if self._is_complex_analysis():
                raise  # FAIL se an√°lise complexa
    
    # Fallback APENAS para opera√ß√µes simples
    if self._is_simple_operation():
        self.logger.info("üîß Stage XX: Usando opera√ß√£o b√°sica")
        return None  # Delega para implementa√ß√£o b√°sica
    else:
        raise Exception("Stage XX requer Anthropic API para an√°lise complexa")

def _is_complex_analysis(self) -> bool:
    """Verifica se √© an√°lise complexa que requer AI"""
    complex_stages = [
        'sentiment_analysis', 'topic_modeling', 'clustering',
        'domain_analysis', 'temporal_analysis', 'network_analysis',
        'qualitative_analysis', 'text_cleaning', 'deduplication'
    ]
    return any(stage in self.current_stage for stage in complex_stages)

def _is_simple_operation(self) -> bool:
    """Verifica se √© opera√ß√£o simples permitida sem AI"""
    simple_operations = [
        'data_validation',  # Valida√ß√£o estrutural
        'file_loading',     # Carregamento de arquivo
        'checkpoint_save'   # Salvar checkpoint
    ]
    return any(op in self.current_stage for op in simple_operations)
```

## Diretrizes de Implementa√ß√£o

### ‚úÖ **O Que DEVE Ser Implementado com Anthropic**

1. **An√°lise Sem√¢ntica**
   - Interpreta√ß√£o de conte√∫do pol√≠tico
   - Classifica√ß√£o de sentimentos
   - Detec√ß√£o de temas e narrativas

2. **Processamento Contextual**
   - Limpeza preservando significado
   - Deduplica√ß√£o sem√¢ntica
   - Normaliza√ß√£o inteligente

3. **An√°lise Complexa**
   - Detec√ß√£o de eventos temporais
   - An√°lise de redes sociais
   - Classifica√ß√£o de desinforma√ß√£o

4. **Interpreta√ß√£o de Resultados**
   - Valida√ß√£o de clusters
   - Interpreta√ß√£o de t√≥picos
   - Revis√£o de qualidade

### ‚ùå **O Que PODE Ser Implementado Tradicionalmente**

1. **Opera√ß√µes de I/O**
   ```python
   # Carregamento b√°sico de arquivo
   df = pd.read_csv(file_path, sep=';', encoding='utf-8')
   
   # Salvamento de checkpoint
   df.to_csv(output_path, sep=';', encoding='utf-8', index=False)
   ```

2. **Valida√ß√µes Estruturais**
   ```python
   # Verifica√ß√£o de colunas obrigat√≥rias
   required_columns = ['texto', 'canal', 'timestamp']
   missing_columns = [col for col in required_columns if col not in df.columns]
   
   # Contagem b√°sica
   total_rows = len(df)
   total_columns = len(df.columns)
   ```

3. **Opera√ß√µes Matem√°ticas Simples**
   ```python
   # Estat√≠sticas descritivas b√°sicas
   null_counts = df.isnull().sum()
   data_types = df.dtypes
   ```

### üö´ **O Que N√ÉO DEVE Ser Implementado Tradicionalmente**

1. **An√°lise de Conte√∫do**
   - ‚ùå Classifica√ß√£o de sentimentos por regras
   - ‚ùå Detec√ß√£o de temas por palavras-chave
   - ‚ùå Limpeza de texto por regex complexos

2. **Interpreta√ß√£o Sem√¢ntica**
   - ‚ùå Agrupamento por similaridade lexical
   - ‚ùå Classifica√ß√£o de dom√≠nios por listas
   - ‚ùå Detec√ß√£o de eventos por thresholds

3. **An√°lise Contextual**
   - ‚ùå Interpreta√ß√£o de redes por m√©tricas b√°sicas
   - ‚ùå Valida√ß√£o de resultados por estat√≠sticas
   - ‚ùå Classifica√ß√£o qualitativa por regras

## Checklist de Implementa√ß√£o

### Para Cada Novo Stage:

- [ ] **M√≥dulo Anthropic criado** em `src/anthropic_integration/`
- [ ] **Classe herda de AnthropicBase**
- [ ] **M√©todo principal implementado** (ex: `analyze_intelligent()`)
- [ ] **Processamento de chunks** para datasets grandes
- [ ] **Prompts contextualizados** para pol√≠tica brasileira
- [ ] **Tratamento de erros** com logging apropriado
- [ ] **Factory integration** em `stage_factory.py`
- [ ] **Executor integration** em `pipeline_executor.py`
- [ ] **Configura√ß√£o** em `settings.yaml`
- [ ] **Fallback m√≠nimo** apenas para opera√ß√µes triviais

### Para Valida√ß√£o:

- [ ] **Stage executa com Anthropic** quando `use_anthropic: true`
- [ ] **Fallback funciona** apenas para opera√ß√µes simples
- [ ] **Erro appropriado** quando AI necess√°ria mas indispon√≠vel
- [ ] **Logging claro** sobre qual m√©todo est√° sendo usado
- [ ] **Resultados consistentes** entre execu√ß√µes
- [ ] **Performance adequada** para datasets grandes

## Conclus√£o

Esta implementa√ß√£o garante que **todos os 13 stages utilizem Anthropic API** para an√°lises complexas, mantendo fallbacks **apenas para opera√ß√µes triviais** como carregamento de arquivos e valida√ß√µes estruturais b√°sicas. 

A arquitetura centralizada elimina a necessidade de scripts separados e garante que **todas as atualiza√ß√µes sejam feitas nos arquivos principais**, conforme especificado nos requisitos do projeto.