# Arquitetura Centralizada do Pipeline Bolsonarismo 2025

## Vis√£o Geral

Este documento descreve a arquitetura completamente centralizada e integrada com Anthropic API implementada em 2025 para o projeto de an√°lise de discurso pol√≠tico brasileiro. A nova arquitetura elimina scripts separados e centraliza toda a execu√ß√£o atrav√©s de um sistema unificado de 13 stages.

## Princ√≠pios Fundamentais

### 1. **Centraliza√ß√£o Absoluta**
- **Uma √∫nica execu√ß√£o**: `python run_centralized_pipeline.py`
- **Configura√ß√£o √∫nica**: `config/settings.yaml`
- **Factory centralizada**: `src/pipeline/stage_factory.py`
- **Executor unificado**: `src/pipeline/pipeline_executor.py`

### 2. **API Anthropic como Padr√£o**
- **Todos os 13 stages** t√™m integra√ß√£o Anthropic
- **Fallback robusto** para m√©todos tradicionais apenas quando necess√°rio
- **Intelig√™ncia artificial** para an√°lise sem√¢ntica e contextual
- **Processamento de chunks** otimizado para grandes datasets

### 3. **Elimina√ß√£o de Scripts Separados**
- **N√£o h√° mais** scripts individuais por stage
- **Fun√ß√µes centralizadas** nos m√≥dulos principais
- **Atualiza√ß√µes** apenas nos arquivos principais
- **Manuten√ß√£o simplificada** e consistente

## Arquitetura do Sistema

### Diagrama de Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PONTO DE ENTRADA √öNICO                          ‚îÇ
‚îÇ                 run_centralized_pipeline.py                        ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚Ä¢ Argumentos CLI                                                  ‚îÇ
‚îÇ  ‚Ä¢ Configura√ß√£o global                                             ‚îÇ
‚îÇ  ‚Ä¢ Controle de execu√ß√£o                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 ORQUESTRADOR PRINCIPAL                             ‚îÇ
‚îÇ                 src/pipeline/runner.py                             ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚Ä¢ Gerenciamento de stages                                         ‚îÇ
‚îÇ  ‚Ä¢ Checkpoint e recupera√ß√£o                                        ‚îÇ
‚îÇ  ‚Ä¢ Logging e relat√≥rios                                            ‚îÇ
‚îÇ  ‚Ä¢ Integra√ß√£o Anthropic central                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ      FACTORY DE STAGES            ‚îÇ    ‚îÇ   EXECUTOR CENTRALIZADO ‚îÇ
    ‚îÇ  src/pipeline/stage_factory.py    ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇsrc/pipeline/pipeline_   ‚îÇ
    ‚îÇ                                   ‚îÇ    ‚îÇ       executor.py       ‚îÇ
    ‚îÇ  ‚Ä¢ Instancia√ß√£o de todos stages   ‚îÇ    ‚îÇ                         ‚îÇ
    ‚îÇ  ‚Ä¢ Detec√ß√£o Anthropic             ‚îÇ    ‚îÇ  ‚Ä¢ M√©todos √∫nicos       ‚îÇ
    ‚îÇ  ‚Ä¢ Configura√ß√£o din√¢mica          ‚îÇ    ‚îÇ  ‚Ä¢ Processamento dados  ‚îÇ
    ‚îÇ  ‚Ä¢ Fallback inteligente           ‚îÇ    ‚îÇ  ‚Ä¢ Integra√ß√£o AI        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 M√ìDULOS ANTHROPIC (13 STAGES)                      ‚îÇ
‚îÇ              src/anthropic_integration/                            ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ smart_encoding_ ‚îÇ ‚îÇ intelligent_    ‚îÇ ‚îÇ semantic_tfidf_ ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ    fixer.py     ‚îÇ ‚îÇ deduplicator.py ‚îÇ ‚îÇ   analyzer.py   ‚îÇ ...  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚Ä¢ Heran√ßa de AnthropicBase                                        ‚îÇ
‚îÇ  ‚Ä¢ Processamento sem√¢ntico                                         ‚îÇ
‚îÇ  ‚Ä¢ An√°lise contextual brasileira                                   ‚îÇ
‚îÇ  ‚Ä¢ Fallback para m√©todos tradicionais                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Fluxo de Dados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Raw    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇInterim  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇProcessed‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇResults  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Final   ‚îÇ
‚îÇ Data    ‚îÇ    ‚îÇ Data    ‚îÇ    ‚îÇ  Data   ‚îÇ    ‚îÇ Analysis‚îÇ    ‚îÇ Report  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ              ‚îÇ              ‚îÇ              ‚îÇ              ‚îÇ
     ‚ñº              ‚ñº              ‚ñº              ‚ñº              ‚ñº
Stages 1-3     Stages 4-8     Stages 9-11   Stages 12-13   Dashboard
(Prep + Clean) (Analysis)     (Network +    (Qualitative  (Visualization)
               (AI Enhanced)   Temporal)     + Review)
```

## Detalhamento dos Componentes

### 1. **Stage Factory (`src/pipeline/stage_factory.py`)**

#### Responsabilidades:
- **Instancia√ß√£o din√¢mica** de todos os 13 stages
- **Detec√ß√£o autom√°tica** da disponibilidade Anthropic
- **Configura√ß√£o inteligente** baseada em `settings.yaml`
- **Fallback robusto** quando API n√£o dispon√≠vel

#### Padr√£o de Implementa√ß√£o:
```python
def _create_stage_XX(self, **kwargs) -> Any:
    """Stage XX: Descri√ß√£o"""
    use_anthropic = self.config.get('config_section', {}).get('use_anthropic', False)
    
    if use_anthropic and self.anthropic_available:
        try:
            from src.anthropic_integration.module_name import ModuleClass
            self.logger.info("ü§ñ Stage XX: Usando an√°lise inteligente")
            return ModuleClass(self.config)
        except Exception as e:
            self.logger.warning(f"Falha na AI Stage XX: {e}. Usando m√©todo tradicional.")
    
    # Fallback tradicional APENAS para fun√ß√µes simples
    self.logger.info("üîß Stage XX: Usando m√©todo b√°sico")
    return None  # Delega para implementa√ß√£o b√°sica
```

#### Stages Mapeados:
- **01_validate_data**: Valida√ß√£o estrutural (sem AI para performance)
- **02_fix_encoding**: Corre√ß√£o inteligente de encoding
- **02b_deduplication**: Deduplica√ß√£o sem√¢ntica
- **01b_feature_extraction**: Extra√ß√£o inteligente de caracter√≠sticas
- **03_clean_text**: Limpeza contextual preservando significado
- **04_sentiment_analysis**: An√°lise multi-dimensional de sentimentos
- **05_topic_modeling**: Interpreta√ß√£o sem√¢ntica de t√≥picos
- **06_tfidf_extraction**: TF-IDF com agrupamento tem√°tico
- **07_clustering**: Valida√ß√£o e interpreta√ß√£o de clusters
- **08_hashtag_normalization**: Normaliza√ß√£o sem√¢ntica de hashtags
- **09_domain_extraction**: Classifica√ß√£o e an√°lise de credibilidade
- **10_temporal_analysis**: Detec√ß√£o e interpreta√ß√£o de eventos
- **11_network_structure**: An√°lise de comunidades e influ√™ncia
- **12_qualitative_analysis**: Classifica√ß√£o de conspira√ß√£o e negacionismo
- **13_review_reproducibility**: Revis√£o inteligente de qualidade

### 2. **Pipeline Executor (`src/pipeline/pipeline_executor.py`)**

#### Responsabilidades:
- **Execu√ß√£o centralizada** de todos os stages
- **Processamento sequencial** com checkpoints
- **Integra√ß√£o direta** com m√≥dulos Anthropic
- **Gerenciamento de dados** entre stages

#### M√©todos Centralizados:
```python
def execute_stage_XX_description(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """Stage XX: Descri√ß√£o - Funcionalidade espec√≠fica"""
    stage_instance = self.stage_factory.create_stage('XX_stage_name')
    
    if hasattr(stage_instance, 'method_intelligent'):  # Usando AI
        return stage_instance.method_intelligent(df, **params)
    else:  # M√©todo tradicional APENAS para tarefas simples
        return self._execute_traditional_method(df)
```

### 3. **M√≥dulos Anthropic (`src/anthropic_integration/`)**

#### Arquitetura dos M√≥dulos:

```python
class IntelligentModule(AnthropicBase):
    """
    M√≥dulo inteligente para an√°lise espec√≠fica
    Herda funcionalidades comuns de AnthropicBase
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        # Configura√ß√µes espec√≠ficas do m√≥dulo
    
    def analyze_intelligent(self, df: pd.DataFrame) -> Dict[str, Any]:
        """M√©todo principal de an√°lise inteligente"""
        # Processamento de chunks
        # Chamadas √† API Anthropic
        # An√°lise contextual brasileira
        # Fallback em caso de erro
```

#### M√≥dulos Implementados:

1. **`smart_encoding_fixer.py`**
   - Corre√ß√£o contextual de encoding
   - Detec√ß√£o inteligente de problemas
   - Preserva√ß√£o de conte√∫do pol√≠tico

2. **`intelligent_deduplicator.py`**
   - Deduplica√ß√£o sem√¢ntica
   - An√°lise de similaridade contextual
   - Preserva√ß√£o de varia√ß√µes importantes

3. **`semantic_tfidf_analyzer.py`**
   - TF-IDF com interpreta√ß√£o sem√¢ntica
   - Agrupamento tem√°tico inteligente
   - Extra√ß√£o de termos politicamente relevantes

4. **`intelligent_domain_analyzer.py`**
   - Classifica√ß√£o autom√°tica de fontes
   - An√°lise de credibilidade
   - Detec√ß√£o de padr√µes de desinforma√ß√£o

5. **`smart_temporal_analyzer.py`**
   - Detec√ß√£o autom√°tica de eventos
   - Correla√ß√£o com contexto hist√≥rico brasileiro
   - An√°lise de campanhas coordenadas

6. **`intelligent_network_analyzer.py`**
   - Detec√ß√£o de comunidades com interpreta√ß√£o
   - An√°lise de influ√™ncia e propaga√ß√£o
   - Identifica√ß√£o de comportamento coordenado

7. **`smart_pipeline_reviewer.py`**
   - Revis√£o inteligente de qualidade
   - An√°lise de vieses metodol√≥gicos
   - Recomenda√ß√µes de melhorias

### 4. **Configura√ß√£o Centralizada (`config/settings.yaml`)**

#### Estrutura de Configura√ß√£o:
```yaml
# Configura√ß√£o global Anthropic
anthropic:
  model: "claude-3-haiku-20240307"
  max_tokens: 4000
  temperature: 0.3
  cost_monitoring: true
  fallback_enabled: true

# Configura√ß√£o por stage
stage_name:
  use_anthropic: true/false
  param1: value1
  param2: value2
```

#### Stages com Anthropic Habilitado:
- **02_fix_encoding**: `use_anthropic: true`
- **02b_deduplication**: `use_anthropic: true`
- **01b_feature_extraction**: `use_anthropic: true`
- **03_clean_text**: `use_anthropic: true`
- **04_sentiment_analysis**: `use_anthropic: true`
- **05_topic_modeling**: `use_anthropic_interpretation: true`
- **06_tfidf_extraction**: `use_anthropic: true`
- **07_clustering**: `use_anthropic_validation: true`
- **08_hashtag_normalization**: `use_anthropic: true`
- **09_domain_extraction**: `use_anthropic: true`
- **10_temporal_analysis**: `use_anthropic: true`
- **11_network_structure**: `use_anthropic: true`
- **12_qualitative_analysis**: `use_anthropic_classification: true`
- **13_pipeline_review**: `use_anthropic: true`

## Padr√µes de Implementa√ß√£o

### 1. **Padr√£o de Fallback Inteligente**

Todos os stages seguem o padr√£o:
```python
if use_anthropic and ANTHROPIC_AVAILABLE:
    try:
        # Implementa√ß√£o com Anthropic API
        result = anthropic_module.intelligent_analysis(data)
    except Exception as e:
        logger.warning(f"API falhou: {e}. Usando m√©todo tradicional.")
        result = traditional_method(data)
else:
    result = traditional_method(data)
```

**Importante**: M√©todos tradicionais s√£o implementados **APENAS** para:
- **Carregamento de arquivos** (leitura CSV b√°sica)
- **Fun√ß√µes muito simples** (contagem, valida√ß√£o estrutural b√°sica)
- **Opera√ß√µes de I/O** (salvar checkpoints)

### 2. **Padr√£o de Processamento de Chunks**

Para datasets grandes:
```python
from src.data.processors.chunk_processor import ChunkProcessor

processor = ChunkProcessor(chunk_size=10000)
for chunk in processor.process_file('large_file.csv'):
    chunk_result = anthropic_module.process_chunk(chunk)
    results.append(chunk_result)
```

### 3. **Padr√£o de An√°lise Contextual Brasileira**

Todos os prompts incluem contexto espec√≠fico:
```python
prompt = f"""
Analise os dados do Telegram brasileiro (2019-2023):

CONTEXTO: 
- Governo Bolsonaro
- Pandemia COVID-19
- Elei√ß√µes 2022
- Movimento bolsonarista
- Negacionismo e autoritarismo

DADOS: {data_sample}

Responda em JSON com an√°lise espec√≠fica...
"""
```

## Benef√≠cios da Arquitetura

### 1. **Centraliza√ß√£o Total**
- ‚úÖ **Um comando**: `python run_centralized_pipeline.py`
- ‚úÖ **Uma configura√ß√£o**: `config/settings.yaml`
- ‚úÖ **Um ponto de manuten√ß√£o**: Arquivos principais
- ‚úÖ **Sem scripts separados**: Elimina√ß√£o de fragmenta√ß√£o

### 2. **Intelig√™ncia Artificial Integrada**
- ‚úÖ **An√°lise sem√¢ntica**: Interpreta√ß√£o contextual do conte√∫do
- ‚úÖ **Compreens√£o pol√≠tica**: Contexto brasileiro espec√≠fico
- ‚úÖ **Qualidade superior**: Resultados mais precisos e relevantes
- ‚úÖ **Automa√ß√£o inteligente**: Redu√ß√£o de interven√ß√£o manual

### 3. **Robustez e Flexibilidade**
- ‚úÖ **Fallback autom√°tico**: Continua funcionando sem API
- ‚úÖ **Configura√ß√£o din√¢mica**: Habilitar/desabilitar AI por stage
- ‚úÖ **Processamento otimizado**: Chunks para grandes datasets
- ‚úÖ **Monitoramento de custos**: Controle de uso da API

### 4. **Manutenibilidade**
- ‚úÖ **C√≥digo centralizado**: Mudan√ßas em poucos arquivos
- ‚úÖ **Padr√µes consistentes**: Mesma estrutura em todos stages
- ‚úÖ **Logging unificado**: Rastreamento completo da execu√ß√£o
- ‚úÖ **Testes integrados**: Valida√ß√£o do pipeline completo

## Comandos de Uso

### Execu√ß√£o Completa
```bash
# Pipeline completo com AI
python run_centralized_pipeline.py

# Pipeline sem AI (apenas m√©todos simples)
python run_centralized_pipeline.py --no-anthropic
```

### Execu√ß√£o Seletiva
```bash
# Stages espec√≠ficos
python run_centralized_pipeline.py --stages 02_fix_encoding 06_tfidf_extraction

# Stage √∫nico
python run_centralized_pipeline.py --single 04_sentiment_analysis
```

### Informa√ß√µes e Debug
```bash
# Listar stages com status AI
python run_centralized_pipeline.py --list

# Debug detalhado
python run_centralized_pipeline.py --log-level DEBUG

# Simula√ß√£o (dry run)
python run_centralized_pipeline.py --dry-run
```

## Diretrizes de Desenvolvimento

### 1. **Regra da Centraliza√ß√£o**
- **NUNCA** criar scripts separados para stages
- **SEMPRE** implementar funcionalidades nos m√≥dulos principais
- **OBRIGAT√ìRIO** usar o stage factory para instancia√ß√£o

### 2. **Regra da Intelig√™ncia Artificial**
- **PADR√ÉO**: Implementar com Anthropic API
- **EXCE√á√ÉO**: M√©todos tradicionais apenas para tarefas triviais
- **PROIBIDO**: An√°lise complexa sem AI

### 3. **Regra da Configura√ß√£o**
- **√öNICA FONTE**: `config/settings.yaml`
- **PAR√ÇMETRO OBRIGAT√ìRIO**: `use_anthropic: true/false`
- **ATUALIZA√á√ÉO**: Apenas nos arquivos principais

### 4. **Regra do Fallback**
- **SEMPRE** implementar fallback robusto
- **APENAS** para fun√ß√µes muito simples
- **LOGGING** obrigat√≥rio quando fallback √© usado

## Conclus√£o

A arquitetura centralizada de 2025 representa uma evolu√ß√£o completa do pipeline Bolsonarismo, eliminando a fragmenta√ß√£o anterior e estabelecendo um sistema unificado, inteligente e maint√≠vel. A integra√ß√£o profunda com Anthropic API garante an√°lises de alta qualidade espec√≠ficas para o contexto pol√≠tico brasileiro, mantendo robustez atrav√©s de fallbacks inteligentes para opera√ß√µes simples.

Esta implementa√ß√£o segue rigorosamente os princ√≠pios de:
- **Centraliza√ß√£o absoluta**
- **Intelig√™ncia artificial como padr√£o**
- **Simplicidade operacional**
- **Manutenibilidade sustent√°vel**

O resultado √© um pipeline que **n√£o requer scripts separados**, **atualiza-se nos arquivos principais** e **utiliza AI para an√°lise complexa**, conforme especificado nos requisitos do projeto.