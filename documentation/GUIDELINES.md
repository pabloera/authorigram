# GUIDELINES - Projeto Bolsonarismo

## Diretrizes de Desenvolvimento e Uso

Este documento estabelece as diretrizes para trabalhar com o projeto Bolsonarismo, que est√° **completamente centralizado na integra√ß√£o Anthropic**.

## üö® ATEN√á√ÉO: LEIA PROJECT_RULES.md PRIMEIRO

**OBRIGAT√ìRIO**: Antes de prosseguir, leia o arquivo `PROJECT_RULES.md` que cont√©m as **REGRAS FIXAS E IMUT√ÅVEIS** do projeto. Este documento (GUIDELINES.md) complementa as regras, mas PROJECT_RULES.md tem preced√™ncia absoluta.

---

## üìã Vis√£o Geral

O projeto Bolsonarismo √© uma an√°lise abrangente do discurso pol√≠tico brasileiro em canais do Telegram (2019-2023), com **arquitetura v4.0 centralizada na API Anthropic**.

### Princ√≠pios Fundamentais

1. **üî• PROCESSAMENTO EM CHUNKS OBRIGAT√ìRIO**: NUNCA carregue arquivos completos - sempre use `ChunkProcessor`
2. **Centraliza√ß√£o Anthropic**: Todas as 13 etapas do pipeline utilizam integra√ß√£o Anthropic como m√©todo principal  
3. **Simplicidade**: Estrutura linear e focada, zero redund√¢ncia
4. **Fonte √önica de Dados**: Apenas `data/DATASETS_FULL/` como origem de dados
5. **Execu√ß√£o Unificada**: Um √∫nico entry point (`run_pipeline.py`)

---

## üóÇÔ∏è Estrutura do Projeto

```
üìÅ dataanalysis-bolsonarismo/
‚îú‚îÄ‚îÄ üéØ run_pipeline.py              # √öNICO entry point
‚îú‚îÄ‚îÄ üìã CLAUDE.md                    # Instru√ß√µes para Claude Code
‚îú‚îÄ‚îÄ üìã GUIDELINES.md                # Este arquivo
‚îú‚îÄ‚îÄ üìã README.md                    # Documenta√ß√£o principal
‚îú‚îÄ‚îÄ üìä data/DATASETS_FULL/          # √öNICA fonte de dados
‚îú‚îÄ‚îÄ ‚öôÔ∏è config/                      # Configura√ß√µes do projeto
‚îú‚îÄ‚îÄ üìù logs/                        # Logs do pipeline
‚îú‚îÄ‚îÄ üóÇÔ∏è archive/scripts_non_pipeline/ # Scripts arquivados
‚îî‚îÄ‚îÄ üß† src/                         # C√≥digo-fonte
    ‚îú‚îÄ‚îÄ ü§ñ anthropic_integration/   # CENTRO: Integra√ß√£o API
    ‚îú‚îÄ‚îÄ ‚ö° pipeline/                # Pipeline runner + stages
    ‚îú‚îÄ‚îÄ üîß data/                    # Processamento de dados
    ‚îî‚îÄ‚îÄ üìö preprocessing/           # Pr√©-processamento
```

---

## üöÄ Como Usar o Projeto

### Setup Inicial

```bash
# 1. Configurar API Anthropic
echo "ANTHROPIC_API_KEY=sk-ant-api03-xxxxx" > .env

# 2. Instalar depend√™ncias
pip install -r pyproject.toml  # ou poetry install

# 3. Executar pipeline completo
python run_pipeline.py
```

### Comandos Principais

```bash
# Executar pipeline completo (13 etapas)
python run_pipeline.py

# Executar etapas espec√≠ficas
python run_pipeline.py --stages 01_validate_data 03_clean_text

# Executar uma √∫nica etapa
python run_pipeline.py --single 04_sentiment_analysis

# Listar todas as etapas
python run_pipeline.py --list

# Resumir execu√ß√£o anterior
python run_pipeline.py  # Detecta checkpoint automaticamente
```

---

## üìä Trabalhando com Dados

### Fonte √önica de Dados

**REGRA OBRIGAT√ìRIA**: Use APENAS chunks para processar dados de `data/DATASETS_FULL/`:

```python
# ‚úÖ M√âTODO OBRIGAT√ìRIO: SEMPRE usar ChunkProcessor
from src.data.processors.chunk_processor import ChunkProcessor

# Configurar processamento em chunks
processor = ChunkProcessor(chunk_size=10000)  # Ajustar conforme mem√≥ria dispon√≠vel

# Processar arquivo em chunks
results = []
for chunk in processor.process_file('data/DATASETS_FULL/1_2019-2021-govbolso.csv'):
    # Processar cada chunk individualmente
    processed_chunk = process_chunk(chunk)
    results.append(processed_chunk)

# ‚ùå NUNCA FAZER: Carregar arquivo completo
# df = pd.read_csv('data/DATASETS_FULL/arquivo.csv', sep=';')  # PROIBIDO!

# ‚úÖ CHUNK SIZES RECOMENDADOS:
# - 10,000 linhas: Para an√°lises complexas
# - 5,000 linhas: Para processamento com API Anthropic
# - 20,000 linhas: Para opera√ß√µes simples
```

### Datasets Dispon√≠veis

1. **1_2019-2021-govbolso.csv** - Per√≠odo do Governo Bolsonaro
2. **2_2021-2022-pandemia.csv** - Per√≠odo da Pandemia
3. **3_2022-2023-poseleic.csv** - Per√≠odo P√≥s-Elei√ß√µes
4. **4_2022-2023-elec.csv** - Per√≠odo Eleitoral
5. **5_2022-2023-elec-extra.csv** - Per√≠odo Eleitoral Estendido
6. **channels_name.csv** - Lista de canais

---

## ü§ñ Integra√ß√£o Anthropic

### Arquitetura Centralizada

O projeto utiliza **integra√ß√£o Anthropic centralizada** atrav√©s de:

- **`src/anthropic_integration/pipeline_integration.py`** - Orquestrador principal
- **`src/anthropic_integration/base.py`** - Cliente API base
- **17 m√≥dulos especializados** - Funcionalidades espec√≠ficas

### Padr√£o de Uso

```python
# O pipeline detecta automaticamente a integra√ß√£o Anthropic
from src.pipeline.runner import PipelineRunner

runner = PipelineRunner()
if runner.anthropic_integration:
    # Usa m√©todos API Anthropic
    runner.run_pipeline()
else:
    # Usa m√©todos tradicionais como fallback
    runner.run_pipeline()
```

### Configura√ß√£o API

```yaml
# config/settings.yaml
anthropic:
  api_key: ${ANTHROPIC_API_KEY}
  model: "claude-3-haiku-20240307"
  max_tokens_per_request: 2000
  temperature: 0.3
```

---

## ‚ö° Pipeline de 13 Etapas

### Core Processing Stages

1. **01_validate_data** - Valida√ß√£o estrutural + detec√ß√£o de encoding
2. **02_fix_encoding** - Corre√ß√£o otimizada de encoding
3. **02b_deduplication** - Deduplica√ß√£o inteligente com contagem de frequ√™ncia
4. **01b_feature_extraction** - Extra√ß√£o de features via API
5. **03_clean_text** - Limpeza textual contextualizada

### Analysis Stages

6. **04_sentiment_analysis** - An√°lise de sentimentos multicamadas
7. **05_topic_modeling** - Modelagem de t√≥picos LDA com interpreta√ß√£o
8. **06_tfidf_extraction** - Extra√ß√£o TF-IDF ponderada por frequ√™ncia
9. **07_clustering** - Clustering com valida√ß√£o API
10. **08_hashtag_normalization** - Normaliza√ß√£o de hashtags
11. **09_domain_extraction** - Extra√ß√£o de dom√≠nios ponderada
12. **10_temporal_analysis** - An√°lise temporal
13. **11_network_structure** - Estrutura de redes
14. **12_qualitative_analysis** - An√°lise qualitativa via API
15. **13_review_reproducibility** - Revis√£o de reprodutibilidade

---

## üîß Desenvolvimento

### Adicionando Nova Funcionalidade

1. **Para funcionalidades API**: Adicionar em `src/anthropic_integration/`
2. **Para etapas do pipeline**: Modificar em `src/pipeline/stages/`
3. **Para processamento de dados**: Adicionar em `src/data/`

### Estrutura de um Stage

```python
# src/pipeline/stages/stage_XX_nome.py
def run_stage(config, stage_config, base_dir, logger, **params):
    """
    Executa a etapa XX do pipeline
    
    Args:
        config: Configura√ß√£o global
        stage_config: Configura√ß√£o da etapa
        base_dir: Diret√≥rio base do projeto
        logger: Logger configurado
        **params: Par√¢metros espec√≠ficos
        
    Returns:
        Dict com resultados da etapa
    """
    logger.info(f"Iniciando stage XX")
    
    # Implementa√ß√£o da etapa
    result = {
        'status': 'completed',
        'metrics': {},
        'output_path': None
    }
    
    return result
```

### Integra√ß√£o com Anthropic

```python
# Exemplo de uso da integra√ß√£o centralizada
from src.anthropic_integration.base import AnthropicBase

class MeuModulo(AnthropicBase):
    def __init__(self, config):
        super().__init__(config)
    
    def processar(self, data):
        prompt = f"Analise este texto: {data}"
        resposta = self.create_message(
            prompt=prompt,
            stage='meu_stage',
            operation='analise_texto'
        )
        return resposta
```

---

## üìù Logs e Monitoramento

### Sistema de Logs

- **Pipeline logs**: `logs/pipeline/`
- **Anthropic costs**: Monitoramento autom√°tico de custos
- **Checkpoints**: Salvamento autom√°tico de progresso

### Estrutura de Logs

```
logs/
‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_YYYYMMDD_HHMMSS.log
‚îÇ   ‚îî‚îÄ‚îÄ api_checkpoints/
‚îî‚îÄ‚îÄ anthropic/
    ‚îî‚îÄ‚îÄ cost_tracking.json
```

---

## üö® Regras Importantes

### ‚úÖ O Que FAZER

1. **SEMPRE use ChunkProcessor para todos os datasets em `data/DATASETS_FULL/`**
2. **Execute via `python run_pipeline.py`**
3. **Configure API Anthropic no arquivo `.env`**
4. **Use chunk_size apropriado (5K-20K linhas)**
5. **Mantenha logs para debugging**
6. **Processe dados em batches, nunca arquivo completo**

### ‚ùå O Que N√ÉO FAZER

1. **‚ùå NUNCA carregue arquivo completo com `pd.read_csv()` - SEMPRE usar chunks**
2. **‚ùå N√£o criar diret√≥rios em `data/` al√©m de `DATASETS_FULL/`**
3. **‚ùå N√£o executar scripts individuais fora do pipeline**
4. **‚ùå N√£o ignorar limita√ß√µes de mem√≥ria - usar chunks menores se necess√°rio**
5. **‚ùå N√£o processar m√∫ltiplos datasets simultaneamente sem chunks**
6. **‚ùå N√£o criar scripts fora da estrutura centralizada**

---

## üõ†Ô∏è Troubleshooting

### Problemas Comuns

**Erro: "API Anthropic n√£o configurada"**
```bash
# Solu√ß√£o
echo "ANTHROPIC_API_KEY=sua_chave_aqui" > .env
```

**Erro: "Dataset n√£o encontrado"**
```bash
# Verificar se arquivo existe
ls data/DATASETS_FULL/
# Usar path correto: data/DATASETS_FULL/nome_arquivo.csv
```

**Pipeline lento ou com problemas de mem√≥ria**
```python
# SEMPRE ajustar chunk_size conforme disponibilidade de mem√≥ria
from src.data.processors.chunk_processor import ChunkProcessor

# Para m√°quinas com pouca mem√≥ria
processor = ChunkProcessor(chunk_size=1000)

# Para processamento com API Anthropic (evitar timeout)
processor = ChunkProcessor(chunk_size=5000)

# Para opera√ß√µes simples em m√°quinas potentes
processor = ChunkProcessor(chunk_size=20000)

# NUNCA processar arquivo completo - mesmo pequenos
```

**Erro: "Memory Error" ou "Out of Memory"**
```python
# Solu√ß√£o: Reduzir drasticamente o chunk_size
processor = ChunkProcessor(chunk_size=500)  # Chunks muito pequenos
```

---

## üìö Refer√™ncias

- **CLAUDE.md** - Instru√ß√µes espec√≠ficas para Claude Code
- **README.md** - Documenta√ß√£o geral do projeto
- **config/settings.yaml** - Configura√ß√µes detalhadas
- **src/anthropic_integration/README.md** - Documenta√ß√£o da integra√ß√£o API

---

## üîÑ Versionamento

- **v4.0** - Arquitetura centralizada Anthropic (atual)
- **v3.0** - Pipeline otimizado h√≠brido
- **v2.0** - Pipeline tradicional
- **v1.0** - Vers√£o inicial

---

*√öltima atualiza√ß√£o: Janeiro 2025*
*Autor: Projeto Bolsonarismo Team*