# Guia de Execu√ß√£o do Pipeline Centralizado Bolsonarismo 2025

## Vis√£o Geral

Este guia fornece instru√ß√µes completas para executar o pipeline centralizado com integra√ß√£o Anthropic API. O sistema elimina a necessidade de scripts separados e centraliza toda a execu√ß√£o atrav√©s de um √∫nico comando.

## Pr√©-requisitos

### 1. **Setup do Ambiente**

```bash
# 1. Ativar ambiente virtual
source activate.sh

# 2. Instalar depend√™ncias
pip install -r requirements.txt

# 3. Configurar API Anthropic
echo "ANTHROPIC_API_KEY=sk-ant-api03-your-key-here" > .env

# 4. Validar configura√ß√£o
python run_centralized_pipeline.py --list
```

### 2. **Estrutura de Dados**

```
data/
‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ telegram_combined_full.csv    # Dataset principal
‚îú‚îÄ‚îÄ interim/                          # Checkpoints autom√°ticos
‚îî‚îÄ‚îÄ processed/                        # Resultados finais
```

### 3. **Verifica√ß√£o de Configura√ß√£o**

```bash
# Verificar se tudo est√° configurado
python -c "
from src.pipeline.stage_factory import get_stage_factory
from pathlib import Path
import yaml

config = yaml.safe_load(open('config/settings.yaml'))
factory = get_stage_factory(config, Path('.'))
info = factory.list_all_stages()

print(f'‚úÖ API Anthropic: {\"Dispon√≠vel\" if info[\"anthropic_available\"] else \"Indispon√≠vel\"}')
print(f'‚úÖ Total Stages: {info[\"total_stages\"]}')

ai_enabled = sum(1 for s in info['stages'].values() if s['will_use_ai'])
print(f'‚úÖ Stages com AI: {ai_enabled}/{info[\"total_stages\"]}')
"
```

## Comandos de Execu√ß√£o

### **Execu√ß√£o Completa (Recomendado)**

```bash
# Pipeline completo com todos os 13 stages
python run_centralized_pipeline.py

# Com n√≠vel de log detalhado
python run_centralized_pipeline.py --log-level DEBUG

# For√ßar rein√≠cio (sem checkpoint)
python run_centralized_pipeline.py --no-resume
```

**Sa√≠da Esperada:**
```
üöÄ Iniciando execu√ß√£o do pipeline completo
üìÇ Carregando dados de: data/raw/telegram_combined_full.csv
‚úÖ Dados carregados: 1,234,567 linhas, 15 colunas
ü§ñ Pipeline executar√° com integra√ß√£o Anthropic CENTRALIZADA

============================
Executando etapa: 01_validate_data
============================
üîß Stage 01: Usando valida√ß√£o tradicional
‚úÖ Etapa 01_validate_data conclu√≠da com sucesso

============================
Executando etapa: 02_fix_encoding
============================
ü§ñ Stage 02: Usando corre√ß√£o inteligente de encoding
‚úÖ Etapa 02_fix_encoding conclu√≠da com sucesso

[... outros stages ...]

üéâ Pipeline conclu√≠do! Dataset final: 1,234,567 linhas
```

### **Execu√ß√£o de Stages Espec√≠ficos**

```bash
# Apenas stages de processamento de texto
python run_centralized_pipeline.py --stages 02_fix_encoding 03_clean_text 04_sentiment_analysis

# Apenas stages de an√°lise avan√ßada
python run_centralized_pipeline.py --stages 10_temporal_analysis 11_network_structure 12_qualitative_analysis

# Apenas revis√£o final
python run_centralized_pipeline.py --stages 13_review_reproducibility
```

### **Execu√ß√£o de Stage Individual**

```bash
# Executar apenas an√°lise de sentimentos
python run_centralized_pipeline.py --single 04_sentiment_analysis

# Executar apenas an√°lise qualitativa
python run_centralized_pipeline.py --single 12_qualitative_analysis

# Executar apenas revis√£o do pipeline
python run_centralized_pipeline.py --single 13_review_reproducibility
```

### **Execu√ß√£o Sem Anthropic API**

```bash
# For√ßar uso de m√©todos tradicionais (apenas para opera√ß√µes simples)
python run_centralized_pipeline.py --no-anthropic

# NOTA: Muitos stages falhar√£o pois requerem AI para an√°lise complexa
```

### **Execu√ß√£o com Dados de Amostra**

```bash
# Processar apenas 10.000 linhas (para testes)
python run_centralized_pipeline.py --sample 10000

# Processar apenas 1.000 linhas (desenvolvimento)
python run_centralized_pipeline.py --sample 1000
```

## Monitoramento da Execu√ß√£o

### **Logs em Tempo Real**

```bash
# Terminal 1: Executar pipeline
python run_centralized_pipeline.py

# Terminal 2: Monitorar logs
tail -f logs/pipeline/pipeline_$(date +%Y%m%d)*.log

# Terminal 3: Monitorar custos Anthropic
watch -n 10 'python -c "
from src.anthropic_integration.cost_monitor import get_cost_report
import json
print(json.dumps(get_cost_report(), indent=2))
"'
```

### **Checkpoints Autom√°ticos**

O pipeline salva checkpoints automaticamente ap√≥s cada stage:

```
data/interim/
‚îú‚îÄ‚îÄ checkpoint_01_validate_data.csv
‚îú‚îÄ‚îÄ checkpoint_02_fix_encoding.csv
‚îú‚îÄ‚îÄ checkpoint_02b_deduplication.csv
‚îú‚îÄ‚îÄ checkpoint_01b_feature_extraction.csv
‚îú‚îÄ‚îÄ checkpoint_03_clean_text.csv
‚îú‚îÄ‚îÄ checkpoint_04_sentiment_analysis.csv
‚îî‚îÄ‚îÄ ...
```

Para retomar execu√ß√£o:
```bash
# Retoma automaticamente do √∫ltimo checkpoint
python run_centralized_pipeline.py

# For√ßar rein√≠cio completo
python run_centralized_pipeline.py --no-resume
```

## Informa√ß√µes e Diagn√≥sticos

### **Listar Todos os Stages**

```bash
python run_centralized_pipeline.py --list
```

**Sa√≠da Esperada:**
```
üìã ETAPAS DO PIPELINE
============================================================

01_validate_data - ‚úÖ Habilitada
  M√≥dulo: stage_01_validate_data
  Depend√™ncias: 
  Par√¢metros: ['skip_structure_check']

02_fix_encoding - ‚úÖ Habilitada
  M√≥dulo: stage_02_fix_encoding
  Depend√™ncias: 01_validate_data
  Par√¢metros: ['columns_to_fix']

[... outros stages ...]

ü§ñ STATUS ANTHROPIC:
API Dispon√≠vel: ‚úÖ
Total de Stages: 13
Stages com AI: 12/13
```

### **Simula√ß√£o (Dry Run)**

```bash
# Simular execu√ß√£o sem processar dados
python run_centralized_pipeline.py --dry-run

# Simular stages espec√≠ficos
python run_centralized_pipeline.py --stages 04_sentiment_analysis 12_qualitative_analysis --dry-run
```

### **An√°lise de Configura√ß√£o**

```bash
# Verificar configura√ß√£o de cada stage
python -c "
import yaml
from pathlib import Path

config = yaml.safe_load(open('config/settings.yaml'))
anthropic_config = config.get('anthropic', {})

print('ü§ñ CONFIGURA√á√ÉO ANTHROPIC')
print(f'Modelo: {anthropic_config.get(\"model\", \"N√£o configurado\")}')
print(f'Max Tokens: {anthropic_config.get(\"max_tokens\", \"N√£o configurado\")}')
print(f'Temperature: {anthropic_config.get(\"temperature\", \"N√£o configurado\")}')

print('\nüìä STAGES COM AI HABILITADA:')
ai_stages = []
for key, value in config.items():
    if isinstance(value, dict):
        for subkey, subvalue in value.items():
            if 'use_anthropic' in subkey and subvalue:
                ai_stages.append(f'{key}.{subkey}')

for stage in ai_stages:
    print(f'  ‚úÖ {stage}')
"
```

## Fluxos de Trabalho Comuns

### **1. Desenvolvimento e Testes**

```bash
# 1. Testar com amostra pequena
python run_centralized_pipeline.py --sample 1000 --single 04_sentiment_analysis

# 2. Executar stages de an√°lise espec√≠ficos
python run_centralized_pipeline.py --sample 5000 --stages 04_sentiment_analysis 12_qualitative_analysis

# 3. Pipeline completo com amostra
python run_centralized_pipeline.py --sample 10000
```

### **2. An√°lise de Produ√ß√£o**

```bash
# 1. Validar configura√ß√£o
python run_centralized_pipeline.py --list

# 2. Executar pipeline completo
python run_centralized_pipeline.py

# 3. Verificar resultados
ls -la data/processed/
cat logs/pipeline/pipeline_report_*.json | jq .
```

### **3. Re-processamento Seletivo**

```bash
# 1. Re-executar apenas an√°lise de texto
python run_centralized_pipeline.py --stages 03_clean_text 04_sentiment_analysis --no-resume

# 2. Re-executar apenas an√°lises avan√ßadas
python run_centralized_pipeline.py --stages 10_temporal_analysis 11_network_structure 12_qualitative_analysis --no-resume

# 3. Re-executar apenas revis√£o
python run_centralized_pipeline.py --single 13_review_reproducibility --no-resume
```

### **4. An√°lise de Custos**

```bash
# Monitorar custos durante execu√ß√£o
python -c "
from src.anthropic_integration.cost_monitor import AnthropicCostMonitor
import yaml

config = yaml.safe_load(open('config/settings.yaml'))
monitor = AnthropicCostMonitor(config)
report = monitor.get_cost_report()

print('üí∞ RELAT√ìRIO DE CUSTOS ANTHROPIC')
print(f'Uso Di√°rio: ${report[\"daily_usage\"]:.4f} / ${report[\"daily_limit\"]:.2f}')
print(f'Uso Mensal: ${report[\"monthly_usage\"]:.4f} / ${report[\"monthly_limit\"]:.2f}')
print(f'Proje√ß√£o Mensal: ${report[\"projected_monthly\"]:.2f}')

print('\nüìä USO POR STAGE:')
for stage, cost in report['usage_by_stage'].items():
    print(f'  {stage}: ${cost:.4f}')
"
```

## Tratamento de Erros

### **Erros Comuns e Solu√ß√µes**

#### **1. API Key N√£o Configurada**

```
‚ùå Erro: ANTHROPIC_API_KEY n√£o configurada

Solu√ß√£o:
echo "ANTHROPIC_API_KEY=sk-ant-api03-your-key" > .env
```

#### **2. Arquivo de Dados N√£o Encontrado**

```
‚ùå Erro: Arquivo de entrada n√£o encontrado: data/raw/telegram_combined_full.csv

Solu√ß√£o:
# Verificar se arquivo existe
ls -la data/raw/

# Especificar arquivo alternativo
python run_centralized_pipeline.py --input data/raw/sample_dataset.csv
```

#### **3. Limite de Custo Atingido**

```
‚ùå Erro: Limite di√°rio de custo atingido ($10.00)

Solu√ß√£o:
# Aumentar limite em config/settings.yaml
anthropic:
  cost_limits:
    daily_limit_usd: 20.0

# Ou resetar contador
python -c "
from src.anthropic_integration.cost_monitor import AnthropicCostMonitor
monitor = AnthropicCostMonitor({})
monitor.reset_daily_usage()
"
```

#### **4. Stage Requer Anthropic Mas API Indispon√≠vel**

```
‚ùå Erro: Stage 04_sentiment_analysis requer Anthropic API para an√°lise complexa

Solu√ß√£o:
# Verificar API key
cat .env | grep ANTHROPIC

# Testar conex√£o
python -c "from src.anthropic_integration.base import AnthropicBase; AnthropicBase({}).test_connection()"

# Usar fallback apenas para stages simples (n√£o recomendado para an√°lise)
python run_centralized_pipeline.py --no-anthropic
```

### **Recovery de Execu√ß√£o Interrompida**

```bash
# Pipeline interrompido? Retomar automaticamente
python run_centralized_pipeline.py

# Verificar √∫ltimo checkpoint
ls -lat data/interim/checkpoint_*.csv | head -5

# Retomar de stage espec√≠fico
python run_centralized_pipeline.py --stages 05_topic_modeling 06_tfidf_extraction 07_clustering
```

## Resultados Esperados

### **Arquivos de Sa√≠da**

```
data/processed/
‚îú‚îÄ‚îÄ final_dataset.csv                 # Dataset final processado
‚îî‚îÄ‚îÄ final_dataset_metadata.json       # Metadados e estat√≠sticas

results/
‚îú‚îÄ‚îÄ text_analysis/                    # An√°lises de texto
‚îú‚îÄ‚îÄ visualizations/                   # Gr√°ficos e visualiza√ß√µes
‚îî‚îÄ‚îÄ final_report/                     # Relat√≥rio final

logs/pipeline/
‚îú‚îÄ‚îÄ pipeline_20250126_143022.log      # Log detalhado da execu√ß√£o
‚îî‚îÄ‚îÄ pipeline_report_20250126_143022.json  # Relat√≥rio estruturado
```

### **M√©tricas de Sucesso**

```json
{
  "pipeline_execution": {
    "total_stages": 13,
    "successful_stages": 13,
    "failed_stages": 0,
    "success_rate": 100.0,
    "total_duration": 3642.5,
    "anthropic_enhanced_stages": 12
  },
  "data_processing": {
    "input_rows": 1234567,
    "output_rows": 1230045,
    "data_quality_score": 0.94,
    "processing_efficiency": 0.89
  },
  "anthropic_usage": {
    "total_api_calls": 247,
    "total_cost_usd": 8.45,
    "average_cost_per_stage": 0.70,
    "ai_enhancement_quality": 0.92
  }
}
```

### **Indicadores de Qualidade**

- **Taxa de Sucesso**: 100% dos stages executados
- **Qualidade dos Dados**: Score > 0.90
- **Efici√™ncia de Processamento**: > 85%
- **Custo por An√°lise**: < $10 por execu√ß√£o completa
- **Reprodutibilidade**: Resultados consistentes entre execu√ß√µes

## Troubleshooting Avan√ßado

### **Debug Detalhado**

```bash
# Ativar logging m√°ximo
python run_centralized_pipeline.py --log-level DEBUG --single 04_sentiment_analysis

# Verificar imports dos m√≥dulos
python -c "
import sys
sys.path.insert(0, 'src')

try:
    from anthropic_integration.sentiment_analyzer import AnthropicSentimentAnalyzer
    print('‚úÖ AnthropicSentimentAnalyzer importado com sucesso')
except Exception as e:
    print(f'‚ùå Erro no import: {e}')

try:
    from pipeline.stage_factory import get_stage_factory
    print('‚úÖ StageFactory importado com sucesso')
except Exception as e:
    print(f'‚ùå Erro no import: {e}')
"

# Verificar configura√ß√£o YAML
python -c "
import yaml
try:
    config = yaml.safe_load(open('config/settings.yaml'))
    print('‚úÖ Configura√ß√£o YAML v√°lida')
    print(f'Anthropic configurado: {\"anthropic\" in config}')
except Exception as e:
    print(f'‚ùå Erro na configura√ß√£o: {e}')
"
```

### **Performance Monitoring**

```bash
# Monitorar uso de mem√≥ria
python run_centralized_pipeline.py --sample 5000 &
PID=$!
while kill -0 $PID 2>/dev/null; do
    ps -p $PID -o %cpu,%mem,rss,vsz,comm
    sleep 30
done

# Monitorar uso de disco
df -h data/
du -sh data/interim/
```

Este guia fornece todas as informa√ß√µes necess√°rias para executar o pipeline centralizado de forma eficiente e monitorar sua execu√ß√£o de perto.